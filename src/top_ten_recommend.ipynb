{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff84fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\TF-IDF_Netflix\\src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_dir = os.path.abspath(os.getcwd())\n",
    "print(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb104274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\TF-IDF_Netflix\\data\\netflix_titles.csv\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.abspath(os.path.join(base_dir, \"..\", \"data\", \"netflix_titles.csv\"))\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79d0aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aefe5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Dick Johnson Is Dead</td>\n",
       "      <td>Kirsten Johnson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>September 25, 2021</td>\n",
       "      <td>2020</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>90 min</td>\n",
       "      <td>Documentaries</td>\n",
       "      <td>As her father nears the end of his life, filmm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Blood &amp; Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>International TV Shows, TV Dramas, TV Mysteries</td>\n",
       "      <td>After crossing paths at a party, a Cape Town t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Ganglands</td>\n",
       "      <td>Julien Leclercq</td>\n",
       "      <td>Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>Crime TV Shows, International TV Shows, TV Act...</td>\n",
       "      <td>To protect his family from a powerful drug lor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  show_id     type                 title         director  \\\n",
       "0      s1    Movie  Dick Johnson Is Dead  Kirsten Johnson   \n",
       "1      s2  TV Show         Blood & Water              NaN   \n",
       "2      s3  TV Show             Ganglands  Julien Leclercq   \n",
       "\n",
       "                                                cast        country  \\\n",
       "0                                                NaN  United States   \n",
       "1  Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...   South Africa   \n",
       "2  Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...            NaN   \n",
       "\n",
       "           date_added  release_year rating   duration  \\\n",
       "0  September 25, 2021          2020  PG-13     90 min   \n",
       "1  September 24, 2021          2021  TV-MA  2 Seasons   \n",
       "2  September 24, 2021          2021  TV-MA   1 Season   \n",
       "\n",
       "                                           listed_in  \\\n",
       "0                                      Documentaries   \n",
       "1    International TV Shows, TV Dramas, TV Mysteries   \n",
       "2  Crime TV Shows, International TV Shows, TV Act...   \n",
       "\n",
       "                                         description  \n",
       "0  As her father nears the end of his life, filmm...  \n",
       "1  After crossing paths at a party, a Cape Town t...  \n",
       "2  To protect his family from a powerful drug lor...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32dabdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8804    Looking to survive in a world taken over by zo...\n",
       "8805    Dragged from civilian life, a former superhero...\n",
       "8806    A scrappy but poor boy worms his way into a ty...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb4e4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8804</th>\n",
       "      <td>Zombieland</td>\n",
       "      <td>Looking to survive in a world taken over by zo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8805</th>\n",
       "      <td>Zoom</td>\n",
       "      <td>Dragged from civilian life, a former superhero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8806</th>\n",
       "      <td>Zubaan</td>\n",
       "      <td>A scrappy but poor boy worms his way into a ty...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                                        description\n",
       "8804  Zombieland  Looking to survive in a world taken over by zo...\n",
       "8805        Zoom  Dragged from civilian life, a former superhero...\n",
       "8806      Zubaan  A scrappy but poor boy worms his way into a ty..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommend = df[['title', 'description']]\n",
    "df_recommend.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cb5e5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_recommend['title'][0]))\n",
    "print(type(df_recommend['description'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55ec215a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e681cffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to c:/Users/user/Desktop/TF-\n",
      "[nltk_data]     IDF_Netflix/venv/Lib/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to c:/Users/user/Desktop/TF-\n",
      "[nltk_data]     IDF_Netflix/venv/Lib/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords', download_dir='c:/Users/user/Desktop/TF-IDF_Netflix/venv/Lib/nltk_data')\n",
    "nltk.download('punkt', download_dir='c:/Users/user/Desktop/TF-IDF_Netflix/venv/Lib/nltk_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0d199b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\user/nltk_data', 'c:\\\\Users\\\\user\\\\Desktop\\\\TF-IDF_Netflix\\\\venv\\\\nltk_data', 'c:\\\\Users\\\\user\\\\Desktop\\\\TF-IDF_Netflix\\\\venv\\\\share\\\\nltk_data', 'c:\\\\Users\\\\user\\\\Desktop\\\\TF-IDF_Netflix\\\\venv\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e8f137f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'czech.pickle',\n",
       " 'danish.pickle',\n",
       " 'dutch.pickle',\n",
       " 'english.pickle',\n",
       " 'estonian.pickle',\n",
       " 'finnish.pickle',\n",
       " 'french.pickle',\n",
       " 'german.pickle',\n",
       " 'greek.pickle',\n",
       " 'italian.pickle',\n",
       " 'malayalam.pickle',\n",
       " 'norwegian.pickle',\n",
       " 'polish.pickle',\n",
       " 'portuguese.pickle',\n",
       " 'PY3',\n",
       " 'README',\n",
       " 'russian.pickle',\n",
       " 'slovene.pickle',\n",
       " 'spanish.pickle',\n",
       " 'swedish.pickle',\n",
       " 'turkish.pickle']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(r'C:\\Users\\user\\Desktop\\TF-IDF_Netflix\\venv\\Lib\\nltk_data\\tokenizers\\punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b640f34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/user/Desktop/TF-IDF_Netflix/venv/Lib/nltk_data', 'C:/Users/user/nltk_data', 'C:\\\\Users\\\\user/nltk_data', 'c:\\\\Users\\\\user\\\\Desktop\\\\TF-IDF_Netflix\\\\venv\\\\nltk_data', 'c:\\\\Users\\\\user\\\\Desktop\\\\TF-IDF_Netflix\\\\venv\\\\share\\\\nltk_data', 'c:\\\\Users\\\\user\\\\Desktop\\\\TF-IDF_Netflix\\\\venv\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data']\n",
      "C:\\Users\\user\\Desktop\\TF-IDF_Netflix\\venv\\Lib\\nltk_data\\tokenizers\\punkt\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.data.path.insert(0, r'C:/Users/user/nltk_data')\n",
    "nltk.data.path.insert(0, r'C:/Users/user/Desktop/TF-IDF_Netflix/venv/Lib/nltk_data')\n",
    "print(nltk.data.path)\n",
    "print(nltk.data.find('tokenizers/punkt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bba39c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(r'C:/Users/user/Desktop/TF-IDF_Netflix/venv/Lib/nltk_data/tokenizers/punkt/english.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09244113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.tokenize.punkt.PunktSentenceTokenizer'>\n"
     ]
    }
   ],
   "source": [
    "from nltk.data import find\n",
    "import pickle\n",
    "\n",
    "punkt_path = find('tokenizers/punkt/english.pickle')\n",
    "with open(punkt_path, 'rb') as f:\n",
    "    english_tokenizer = pickle.load(f)\n",
    "print(type(english_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "753bb9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Family is not an important thing.', \"It's everything.\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.data import find\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "\n",
    "# punkt 인스턴스 미리 불러오기\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punkt_path = find('tokenizers/punkt/english.pickle')\n",
    "with open(punkt_path, 'rb') as f:\n",
    "    english_tokenizer = pickle.load(f)\n",
    "\n",
    "text = \"Family is not an important thing. It's everything.\"\n",
    "print(english_tokenizer.tokenize(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfa2e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.data import find\n",
    "import pickle\n",
    "\n",
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    # 1. 직접 불러온 tokenizer로 문장 분리\n",
    "    sentences = english_tokenizer.tokenize(sentence)\n",
    "    result = []\n",
    "    for sentence in sentences:\n",
    "        word_tokens = treebank_tokenizer.tokenize(sentence) # 하나씩 문자열을 집어넣어야 함\n",
    "        for word in word_tokens:\n",
    "            word = word.lower() # 소문자로 통일 안하면 기계는 다른 걸로 인식함\n",
    "        \n",
    "            if word not in stop_words and word.isalnum(): # 불용어와 구두점 제거하는 함수\n",
    "                    result.append(word)\n",
    "    return ' '.join(result) #  리스트에 있는 문자열을 공백(' ')으로 이어서 하나의 문자열로 만드는 방법\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3b7f074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'family important thing everything'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d639a72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_25556\\3729845377.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recommend['description'] = df_recommend['description'].apply(preprocessing)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8804</th>\n",
       "      <td>Zombieland</td>\n",
       "      <td>looking survive world taken zombies dorky coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8805</th>\n",
       "      <td>Zoom</td>\n",
       "      <td>dragged civilian life former superhero must tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8806</th>\n",
       "      <td>Zubaan</td>\n",
       "      <td>scrappy poor boy worms way tycoon dysfunctiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                                        description\n",
       "8804  Zombieland  looking survive world taken zombies dorky coll...\n",
       "8805        Zoom  dragged civilian life former superhero must tr...\n",
       "8806      Zubaan  scrappy poor boy worms way tycoon dysfunctiona..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommend['description'] = df_recommend['description'].apply(preprocessing)\n",
    "df_recommend.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6519ee88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'father nears end life filmmaker kirsten johnson stages death inventive comical ways help face inevitable'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommend['description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45554dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\desktop\\tf-idf_netflix\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff2a01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 113156 stored elements and shape (8807, 9737)>\n",
      "  Coords\tValues\n",
      "  (0, 3260)\t0.17599249507760978\n",
      "  (0, 5800)\t0.324741472122099\n",
      "  (0, 2884)\t0.24549002149623622\n",
      "  (0, 5049)\t0.13679938531649524\n",
      "  (0, 3356)\t0.24549002149623622\n",
      "  (0, 4708)\t0.33816898858332023\n",
      "  (0, 8174)\t0.29708021462733747\n",
      "  (0, 2219)\t0.19538468424205493\n",
      "  (0, 4569)\t0.33089312615357\n",
      "  (0, 1731)\t0.33089312615357\n",
      "  (0, 9460)\t0.24175769963781432\n",
      "  (0, 4051)\t0.17585559354021849\n",
      "  (0, 3187)\t0.2159189852970443\n",
      "  (0, 4412)\t0.3585543836483316\n",
      "  (1, 2065)\t0.3471901547728639\n",
      "  (1, 6231)\t0.24894519191310555\n",
      "  (1, 6210)\t0.2421007635806912\n",
      "  (1, 1330)\t0.3471901547728639\n",
      "  (1, 8827)\t0.20059686444468997\n",
      "  (1, 8595)\t0.19347168927119945\n",
      "  (1, 7712)\t0.21338764235317584\n",
      "  (1, 6733)\t0.24748177449931338\n",
      "  (1, 9515)\t0.2829218715226013\n",
      "  (1, 8481)\t0.33972019777392803\n",
      "  (1, 8191)\t0.21307607178850632\n",
      "  :\t:\n",
      "  (8805, 3505)\t0.18059192014420306\n",
      "  (8805, 652)\t0.2142908269565319\n",
      "  (8805, 7528)\t0.30672942991092106\n",
      "  (8805, 8397)\t0.24353778977113155\n",
      "  (8805, 5507)\t0.23230658718863\n",
      "  (8805, 9335)\t0.2651607128722021\n",
      "  (8805, 1592)\t0.29242951653479654\n",
      "  (8805, 3225)\t0.2744137563026985\n",
      "  (8805, 6581)\t0.29242951653479654\n",
      "  (8805, 9709)\t0.31687537991662906\n",
      "  (8805, 2059)\t0.30672942991092106\n",
      "  (8805, 2633)\t0.31687537991662906\n",
      "  (8806, 3227)\t0.15933216488447483\n",
      "  (8806, 6224)\t0.21039000821516374\n",
      "  (8806, 9458)\t0.21682106600361292\n",
      "  (8806, 1103)\t0.21602856935396117\n",
      "  (8806, 3192)\t0.29184246348379467\n",
      "  (8806, 7590)\t0.3301858280920517\n",
      "  (8806, 9018)\t0.3176848831090267\n",
      "  (8806, 5721)\t0.23085956677402936\n",
      "  (8806, 8975)\t0.24940918782191168\n",
      "  (8806, 3268)\t0.31021729714216406\n",
      "  (8806, 6493)\t0.29336732269592347\n",
      "  (8806, 2716)\t0.3176848831090267\n",
      "  (8806, 9634)\t0.37792495782394414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# 1. TF-IDF 벡터화: 전처리된 설명 문자열에서 단어의 중요도를 벡터로 변환\n",
    "\n",
    "tf_idf = TfidfVectorizer(\n",
    "    min_df = 2, # 2개 미만의 문서에만 등장하는 단어는 단어사전에서 제외\n",
    "    # min_df가 너무 높으면 중요한 희귀 단어까지 제거될 수 있음\n",
    "    # 장르, 인물, 장소명 등 영화만의 “특징어”까지 빠질 위험\n",
    "    # 보통 피처(단어) 개수는 수천~수만 개가 일반적이다.\n",
    "    # 이 숫자의 범위에 들어오도록 조정하는 것.\n",
    "    # 숫자로 해도 되고 비율로 해도 된다.\n",
    "    \n",
    "    max_df = 0.99 # 99% 이상의 문서에 등장하면 너무 흔해서 제외\n",
    "    # max_df가 너무 낮으면 중요하지만 기본적으로 많이 등장하는 단어(중요 키워드)도 빠질 수 있음\n",
    "    \n",
    "    # stop_words='english'\n",
    "    # 불용어 제거를 이미 했지만 사실 벡터라이저 옵션으로 넣을 수 있다.\n",
    ") \n",
    "# TF-IDF 벡터라이저 객체 생성\n",
    "# 문서 하나 두개에만 나오고 나머지는 안나오는 단어들이 있을 수 있다.\n",
    "# 이런거는 나머지가 다 0 이다.\n",
    "# 데이터가 작으면 몰라도 크면 이런 쓸데 없는거 때문에\n",
    "# 메모리 잡아먹어서 문제 생길 수 있다.\n",
    "# 그래서 min 을 정해서 최소 몇개 문서에서 나와야\n",
    "# 단어 사전에 등록시킬지를 정하는 것.\n",
    "\n",
    "tf_idf_matrix = tf_idf.fit_transform(df_recommend['description']) # 각 영화 설명을 벡터로 변환 (문서 × 단어 행렬)\n",
    "print(tf_idf_matrix)\n",
    "\n",
    "# 출력하면 결과가 이상함. 열이 두개밖에 안나옴 Coords, Values \n",
    "# 실제로 tfidf_matrix는 [문서 수, 단어 수] 크기의 2차원 행렬(매트릭스)\n",
    "# 하지만, 대부분의 단어에 대해 0(등장하지 않음)이 많아서,\n",
    "# 메모리 효율을 위해 “희소행렬(sparse matrix)” 형태로 저장\n",
    "\n",
    "# (i, j) values 는 i 번째 행의 j 번째 단어의 TF-IDF 값이 values 라는 뜻."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a718471a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 단어 개수: 9737\n"
     ]
    }
   ],
   "source": [
    "print(\"전체 단어 개수:\", len(tf_idf.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2735f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "# 2. 코사인 유사도 행렬 계산: 각 영화 설명 벡터 간의 유사도(0~1)를 계산\n",
    "\n",
    "cosine_sim = linear_kernel(tf_idf_matrix, tf_idf_matrix)\n",
    "# cosine_sim[i][j]: i번째 영화와 j번째 영화 설명 벡터의 코사인 유사도(1에 가까울수록 비슷함)\n",
    "\n",
    "# 3. 영화 제목을 입력하면 비슷한 영화 10개 추천하는 함수\n",
    "def top_ten_sim(title, df, cosine_sim):\n",
    "    index_num = df[ df['title'] == title ].index[0] \n",
    "    # 입력한 title 과 같은 값을 가진 title 을 가진 행의 인덱스를 가져옴\n",
    "    # 근데 두개 이상 있을 수 있으니 첫번째 거만 가져옴\n",
    "    sim_scores = list(enumerate(cosine_sim[index_num]))\n",
    "    # (인덱스, 유사도) 튜플을 하나의 리스트로 만듦\n",
    "    # 인덱싱이나 슬라이싱 정렬 등을 하기 위해서임.\n",
    "    #[ (0, 0.17), (1, 0.32),... ] 이런식이다.\n",
    "    # enumerate() 는 리스트, 튜플, 문자열 등\n",
    "    # 순서가 있는(iterable) 자료형에 “순서(인덱스)와 값”을 동시에 반환해 준다.\n",
    "    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "    # 유사도 기준으로 내림차순 정렬\n",
    "    # sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "    # 여기서 sim_scores 는 정렬대상(현재는 리스트)\n",
    "    # key=lambda x: x[1] 는 각 원소(튜플)중 어떤 값을 기준으로 정렬할지 지정함\n",
    "    # x[1] 이니까 벡터를 기반으로 계산된 코사인 유사도를 기준으로\n",
    "    # reverse = True 내림차순 정렬함.\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    # 자기 자신(0번째) 제외, 상위 10개 추출\n",
    "    sim_indexes = [ i[0] for i in sim_scores]\n",
    "    # 10개의 코사인 유사도에 대한 영화 인덱스를 순차적으로 추출해서\n",
    "    # 리스트로 감싸줌\n",
    "    \n",
    "    return df['title'].iloc[sim_indexes]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edcbca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_and_sim(title, df, cosine_sim):\n",
    "    index_num = df[df['title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[index_num]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    sim_indexes = [ i[0] for i in sim_scores]\n",
    "    sim_values = [i[1] for i in sim_scores]\n",
    "    \n",
    "    result_df = df.iloc[sim_indexes][['title']].copy()\n",
    "    result_df['similarity'] = sim_values\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "    # 깔끔하게 인덱스 지움\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ad793ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5344    Message from the King\n",
      "4271               Lion Pride\n",
      "1884      Walk Away from Love\n",
      "4285                    Lilli\n",
      "4209               Next Enti?\n",
      "6713          Everybody Knows\n",
      "613                 Voiceless\n",
      "1905             Cold Harbour\n",
      "108                 Dive Club\n",
      "6289                  Bewafaa\n",
      "Name: title, dtype: object\n",
      "                   title  similarity\n",
      "0  Message from the King    0.214179\n",
      "1             Lion Pride    0.195297\n",
      "2    Walk Away from Love    0.177384\n",
      "3                  Lilli    0.173507\n",
      "4             Next Enti?    0.166291\n",
      "5        Everybody Knows    0.158209\n",
      "6              Voiceless    0.156730\n",
      "7           Cold Harbour    0.147404\n",
      "8              Dive Club    0.147104\n",
      "9                Bewafaa    0.138824\n"
     ]
    }
   ],
   "source": [
    "print(top_ten_sim('Blood & Water', df_recommend, cosine_sim))\n",
    "print(title_and_sim('Blood & Water', df_recommend, cosine_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce030e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
